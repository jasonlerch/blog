{
  "hash": "d1458555a3530b4fce1cdb89ac983f2b",
  "result": {
    "markdown": "---\ntitle: \"Developmental analyses, part 1\"\ndescription: \"How to deal with longitudinal brain development data\"\nauthor: \"Jason Lerch\"\ndate: \"2023/11/26\"\ncategories: [R, longitudinal]\ndraft: false\n---\n\n\nLongitudinal data provides its own set of modelling challenges. These primarily concern how to model time, especially if there is a curvilinear relationship between time and variable(s) of interest. A related issue is making statistical models not only fit the data well but also produce interpretable output that helps address questions of changes in baseline alongside changes in trajectories.\n\nThis will be a series of posts, exploring:\n\n1.  Plotting of longitudinal data\n2.  Fitting straight lines and interpreting slopes and intercepts\n3.  Fitting curves via splines\n4.  Comparisons between different fitted models for ease of interpretation\n5.  Segmented models\n6.  General additive models\n7.  Random intercepts and random slopes\n8.  Bayesian linear models\n9.  RMINC and data.tree methods to explore all these across the brain\n\nFor this first post we'll look at points 1-4 with small bits of RMINC and data.tree creeping in.\n\nTo explore these questions we will use data being collected by Tiffany Chien, where she is looking at the effect of maternal auto-antibodies on brain development in mice. Each mouse was imaged at eight different timepoints, following a pattern set [here](https://www.nature.com/articles/s41467-018-04921-2) and first developed [here](https://pubmed.ncbi.nlm.nih.gov/26037053/). We begin by loading the data as provided by Tiffany:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.tree)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nload(\"brain_analysis_data_2023nov2.RData\")\n```\n:::\n\n\nThis contains 5 items - the anatomy and labels volumes, the dataframe describing each scan (gf), a matrix of structure volumes (structvols), and the label definitions (hdefs).\n\nWe can then add the volumes to the hierarchical anatomy, since anatomical hierarchies are awesome.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RMINC)\n# the suppress warnings bit deals with a comparison in the data.tree\n# library that throws far too many warnings.\nhvols <- suppressWarnings(addVolumesToHierarchy(hdefs, structvols))\n```\n:::\n\n\nLet's start with overall brain volumes\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf$brainVols <- hvols$volumes\n```\n:::\n\n\nAnd plot them, initially by sex, since we have some decently strong expectations of the development of sex differences in the brain.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# set some defaults for ggplots for the rest of the document\ntheme_set(theme_minimal())\nscale_colour_brewer_d <- function(...) {\n  scale_colour_brewer(palette = \"Set1\", ...)\n}\n\noptions(ggplot2.discrete.colour=scale_colour_brewer_d)\n\nggplot(gf) + \n  aes(x=age, y=brainVols, colour=Sex) + \n  geom_point() + \n  geom_smooth() + \n  ylab(bquote(Volume ~ (mm^3))) + \n  ggtitle(\"Brain volume\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThis is a fairly standard ggplot plot. geom_smooth does a lot of the heavy lifting here. By default it uses a local estimator (loess) to fit the curve; these are great for visualization but not so useful for analyses. It also shows a clear overall pattern of rapid growth in brain volume until around day 20, followed by slower growth.\n\nBrain volume does not appear particularly different by sex, which is what we have seen before. Since we are looking at sex let's pick a classically dimorphic brain structure\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(gf %>% \n         mutate(MeA = FindNode(hvols, \"Medial amygdalar nucleus\")$volumes)) + \n  aes(x=age, y=MeA, colour=Sex) + \n  geom_point() + \n  geom_smooth() + \n  ylab(bquote(Volume ~ (mm^3))) + \n  ggtitle(\"Medial Amygdala\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nOK, we have sensible patterns, showing larger volumes of the medial amygdala in males, seemingly emerging over the first few days of life. Let's improve the plot a little bit to let us see what happens to individual mice. First, let's plot each mouse entirely separately.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(gf %>% \n         mutate(MeA = FindNode(hvols, \"Medial amygdalar nucleus\")$volumes)) + \n  aes(x=age, y=MeA, colour=Sex) + \n  geom_point() + \n  geom_line() + \n  ylab(bquote(Volume ~ (mm^3))) + \n  ggtitle(\"Medial Amygdala\") + \n  facet_wrap(~subject_id)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nNote that I've replaced the fitting (`geom_smooth`) with a simpler line (`geom_line`). A few features immediately stand out from this plot: quite a few mice only have a few data points, which is primarily due to data collection being ongoing, and there are too many mice for this plot to be terribly useful. Let's instead plot separate lines on the same plot as before:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(gf %>% \n         mutate(MeA = FindNode(hvols, \"Medial amygdalar nucleus\")$volumes)) + \n  aes(x=age, y=MeA, colour=Sex) + \n  geom_point() + \n  geom_smooth() + \n  geom_line(aes(group=subject_id), alpha=0.2) + \n  ylab(bquote(Volume ~ (mm^3))) + \n  ggtitle(\"Medial Amygdala\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nNot always clear how useful such a plot is, but it sure is pretty. Note that the `geom_line` bit needed to have the `group` specified in order for ggplot to know which points to join up with lines.\n\nOn to statistics. For the sake of argument let's go with the simplest model of volume against age by sex:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressMessages(library(lmerTest))\n# create a new variable for the medial amygdala for easier access\ngf <- gf %>% \n  mutate(MeA = FindNode(hvols, \"Medial amygdalar nucleus\")$volumes)\n\n# run the linear mixed effects model.\nsummary(lmer(MeA ~ age * Sex + (1|subject_id), gf))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nboundary (singular) fit: see help('isSingular')\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: MeA ~ age * Sex + (1 | subject_id)\n   Data: gf\n\nREML criterion at convergence: -362.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6383 -0.7678  0.0283  0.7920  3.6123 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.000000 0.0000  \n Residual               0.009781 0.0989  \nNumber of obs: 224, groups:  subject_id, 37\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(>|t|)    \n(Intercept) 5.125e-01  1.425e-02 2.200e+02  35.967   <2e-16 ***\nage         7.674e-03  4.859e-04 2.200e+02  15.794   <2e-16 ***\nSexM        5.855e-03  1.942e-02 2.200e+02   0.302   0.7633    \nage:SexM    1.717e-03  6.762e-04 2.200e+02   2.539   0.0118 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) age    SexM  \nage      -0.739              \nSexM     -0.734  0.542       \nage:SexM  0.531 -0.719 -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n:::\n:::\n\n\nHere we use a linear mixed effects model. These models are the bread and butter of longitudinal analyses, as they allow you to account for the dependence created by having multiple datapoints from the same subject. There are multiple ways to specify these models, with the main decisions revolving around what fixed effects and what random effects to use. Fixed effects are what you would use in any old linear model; here we specify an age by sex interaction. Random effects, the bits inside the parentheses, determine how to treat the individual mice in this dataset. Here we use the simplest formula, (1 \\| id), which allows every mouse to have a separate intercept but not a separate slope. I.e. at baseline mouse 1 can have a larger or smaller volume than mouse 2, but from then on the effect of age will be the same for all mice. We could allow for separate slopes too, a topic which we will explore in a future post.\n\nWe also get warnings about singular fits - these are due to no variance in the random intercept (i.e. the separate intercept per subject) being identified. This can be indicative of a real problem and the need to change the model formula, but in simple cases like this [can be ignored for now](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#singular-models-random-effect-variances-estimated-as-zero-or-correlations-estimated-as---1).\n\nOnto the results. Our model shows an effect of age and an age by sex interaction, but no effect of sex. Why is that? Two reasons:\n\n1.  We are fitting a straight line, where there clearly is a curve in the data\n2.  We are testing the effect of sex at age=0, which doesn't make sense.\n\nLet's look at them in turn. Plotting as a straight line:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(gf) +\n  aes(x=age, y=MeA, colour=Sex) + \n  geom_point() + \n  geom_smooth(method=\"lm\", formula=y~x) + \n  ylab(bquote(Volume ~ (mm^3))) + \n  ggtitle(\"Medial Amygdala\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nFirst, it's evident that the model does not fit all that well, which is to be expected since we saw earlier that a straight line is not the right way to model age. Second, we can see the interaction - the lines are not parallel. Third, at age=0 the lines overlap.\n\nTackling the third point first, in a linear model with an interaction, each term of an interaction is interpreted at the zero point of the other term. Going back to the linear model output from above, it's telling us that age=0 the females (the reference level of sex) have a volume of 5.125e-01 (the intercept), and males a volume of 5.125e-01 + 5.855e-03. If we change where the intercept falls we change these values. To whit, let's test at an age of 65:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lmer(MeA ~ age * Sex + (1|subject_id), gf %>% mutate(age = age-65)))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nboundary (singular) fit: see help('isSingular')\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: MeA ~ age * Sex + (1 | subject_id)\n   Data: gf %>% mutate(age = age - 65)\n\nREML criterion at convergence: -362.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6383 -0.7678  0.0283  0.7920  3.6123 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.000000 0.0000  \n Residual               0.009781 0.0989  \nNumber of obs: 224, groups:  subject_id, 37\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(>|t|)    \n(Intercept) 1.011e+00  2.315e-02 2.200e+02  43.693  < 2e-16 ***\nage         7.674e-03  4.859e-04 2.200e+02  15.794  < 2e-16 ***\nSexM        1.175e-01  3.256e-02 2.200e+02   3.607 0.000383 ***\nage:SexM    1.717e-03  6.762e-04 2.200e+02   2.539 0.011796 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) age    SexM  \nage       0.910              \nSexM     -0.711 -0.647       \nage:SexM -0.654 -0.719  0.914\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n:::\n:::\n\n\nI changed age by subtracting 65 from it, so now the intercept (age=0) is really age=65. Now the SexM term has become quite significant; look back at the plot above and see how the two lines diverge significantly at that age. At age 65 the females have a volume 1.01, and males 1.01 + 0.11.\n\n### Fitting curves in linear models\n\nNow back to the fact that the data should not be fit with a straight line since there is a clearly detectable curve in the relation between volume and age. Let's use a third order spline:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\nggplot(gf) +\n  aes(x=age, y=MeA, colour=Sex) + \n  geom_point() + \n  geom_smooth(method=\"lm\", formula=y~ns(x,3) ) + \n  ylab(bquote(Volume ~ (mm^3))) + \n  ggtitle(\"Medial Amygdala\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nHere I changed the bit inside `geom_smooth`. First, using the `method=\"lm\"` syntax I told it to use a linear model rather than a local estimator, and then I gave it the formula. The `ns(age, 3)` syntax tells it to use a natural spline with 3 degrees of freedom.\n\nThat fits pretty well. Let's look at the model outputs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lmer(MeA ~ ns(age,3) * Sex + (1|subject_id), gf))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: MeA ~ ns(age, 3) * Sex + (1 | subject_id)\n   Data: gf\n\nREML criterion at convergence: -684.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4337 -0.5530  0.1326  0.5837  4.8808 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.000588 0.02425 \n Residual               0.001906 0.04366 \nNumber of obs: 224, groups:  subject_id, 37\n\nFixed effects:\n                  Estimate Std. Error        df t value Pr(>|t|)    \n(Intercept)      4.357e-01  1.200e-02 1.420e+02  36.326  < 2e-16 ***\nns(age, 3)1      4.611e-01  2.098e-02 1.873e+02  21.977  < 2e-16 ***\nns(age, 3)2      6.464e-01  2.463e-02 1.898e+02  26.238  < 2e-16 ***\nns(age, 3)3      3.878e-01  1.304e-02 1.856e+02  29.730  < 2e-16 ***\nSexM             3.758e-03  1.596e-02 1.356e+02   0.235 0.814249    \nns(age, 3)1:SexM 5.144e-02  2.931e-02 1.895e+02   1.755 0.080902 .  \nns(age, 3)2:SexM 1.110e-01  3.287e-02 1.893e+02   3.378 0.000888 ***\nns(age, 3)3:SexM 7.340e-02  1.833e-02 1.860e+02   4.005 8.94e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) ns(,3)1 ns(,3)2 ns(,3)3 SexM   n(,3)1: n(,3)2:\nns(age, 3)1 -0.002                                               \nns(age, 3)2 -0.782 -0.029                                        \nns(age, 3)3 -0.193  0.167   0.314                                \nSexM        -0.751  0.002   0.587   0.145                        \nns(g,3)1:SM  0.002 -0.716   0.021  -0.120  -0.002                \nns(g,3)2:SM  0.586  0.022  -0.749  -0.235  -0.766 -0.030         \nns(g,3)3:SM  0.137 -0.119  -0.223  -0.712  -0.178  0.151   0.311 \n```\n:::\n:::\n\n\nNow we have a much harder to interpret set of age terms (and their interactions). Each of the `ns(age, 3)1` or `ns(age, 3)2` or `ns(age, 3)3` tells us about the parameters of the different spline terms. While these can obviously be used to reconstruct the fit, in practice they are essentially uninterpretable for figuring out where and how the age trajectories deviate by sex.\n\nBut looking at just the sex terms, it's again insignificant at age=0. Let's see at age 65.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lmer(MeA ~ ns(age,3) * Sex + (1|subject_id), gf %>% mutate(age=age-65)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: MeA ~ ns(age, 3) * Sex + (1 | subject_id)\n   Data: gf %>% mutate(age = age - 65)\n\nREML criterion at convergence: -684.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4337 -0.5530  0.1326  0.5837  4.8808 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.000588 0.02425 \n Residual               0.001906 0.04366 \nNumber of obs: 224, groups:  subject_id, 37\n\nFixed effects:\n                  Estimate Std. Error        df t value Pr(>|t|)    \n(Intercept)      4.357e-01  1.200e-02 1.420e+02  36.326  < 2e-16 ***\nns(age, 3)1      4.611e-01  2.098e-02 1.873e+02  21.977  < 2e-16 ***\nns(age, 3)2      6.464e-01  2.463e-02 1.898e+02  26.238  < 2e-16 ***\nns(age, 3)3      3.878e-01  1.304e-02 1.856e+02  29.730  < 2e-16 ***\nSexM             3.758e-03  1.596e-02 1.356e+02   0.235 0.814249    \nns(age, 3)1:SexM 5.144e-02  2.931e-02 1.895e+02   1.755 0.080902 .  \nns(age, 3)2:SexM 1.110e-01  3.287e-02 1.893e+02   3.378 0.000888 ***\nns(age, 3)3:SexM 7.340e-02  1.833e-02 1.860e+02   4.005 8.94e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) ns(,3)1 ns(,3)2 ns(,3)3 SexM   n(,3)1: n(,3)2:\nns(age, 3)1 -0.002                                               \nns(age, 3)2 -0.782 -0.029                                        \nns(age, 3)3 -0.193  0.167   0.314                                \nSexM        -0.751  0.002   0.587   0.145                        \nns(g,3)1:SM  0.002 -0.716   0.021  -0.120  -0.002                \nns(g,3)2:SM  0.586  0.022  -0.749  -0.235  -0.766 -0.030         \nns(g,3)3:SM  0.137 -0.119  -0.223  -0.712  -0.178  0.151   0.311 \n```\n:::\n:::\n\n\nThe model terms haven't changed. So with splines we've lost the ability to interpret our data quite the way we want by moving the intercept; other spline parameterizations than natural splines can do better, and polynomials can do it very well, but ultimately we want a more general solution. The [emmeans](https://github.com/rvlenth/emmeans) package to the rescue for estimated marginal means.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nl <- lmer(MeA ~ ns(age,3) * Sex + (1|subject_id), gf)\ne <- emmeans(l, ~ Sex | age, at = list(age=c(7, 21, 65)))\n```\n:::\n\n\nFirst, we fitted a linear mixed effects model as before, and then we've computed the marginal means using the `emmeans` function from the package of the same name. The first argument is the model, then it's the formula; here we tell it that we want to evaluate Sex across age. Next we tell the `emmeans` function to evaluate its output at 3 different ages - 7, 21, and 65. We can look at the output:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ne\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nage =  7:\n Sex emmean      SE    df lower.CL upper.CL\n F    0.525 0.00863  56.6    0.508    0.543\n M    0.547 0.00807  56.0    0.531    0.563\n\nage = 21:\n Sex emmean      SE    df lower.CL upper.CL\n F    0.766 0.00908  65.2    0.748    0.784\n M    0.820 0.00866  71.0    0.802    0.837\n\nage = 65:\n Sex emmean      SE    df lower.CL upper.CL\n F    0.911 0.01320 172.9    0.885    0.937\n M    1.006 0.01310 184.7    0.980    1.032\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n```\n:::\n:::\n\n\nThis is already quite useful, as we can get the estimated means at those three ages for each sex, alongside their 95% confidence intervals. But we can go further and compute the differences at those ages explicitly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(e)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nage =  7:\n contrast estimate     SE    df t.ratio p.value\n F - M     -0.0216 0.0118  56.4  -1.832  0.0722\n\nage = 21:\n contrast estimate     SE    df t.ratio p.value\n F - M     -0.0538 0.0125  67.9  -4.289  0.0001\n\nage = 65:\n contrast estimate     SE    df t.ratio p.value\n F - M     -0.0951 0.0186 178.8  -5.115  <.0001\n\nDegrees-of-freedom method: kenward-roger \n```\n:::\n:::\n\n\nWe can tell from this output that sex differences are borderline at age 7, and become quite strikingly significant later. Note that the contrast is the reverse of what we would expect from our linear model; we can reverse that in turn:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(e, reverse = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nage =  7:\n contrast estimate     SE    df t.ratio p.value\n M - F      0.0216 0.0118  56.4   1.832  0.0722\n\nage = 21:\n contrast estimate     SE    df t.ratio p.value\n M - F      0.0538 0.0125  67.9   4.289  0.0001\n\nage = 65:\n contrast estimate     SE    df t.ratio p.value\n M - F      0.0951 0.0186 178.8   5.115  <.0001\n\nDegrees-of-freedom method: kenward-roger \n```\n:::\n:::\n\n\nAs a way of comparison, let's get back to overall brain volume, which at least visually appeared to not differ much by sex:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nl <- lmer(brainVols ~ ns(age,3) * Sex + (1|subject_id), gf)\n(e <- emmeans(l, ~ Sex | age, at = list(age=c(7, 21, 65))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nage =  7:\n Sex emmean   SE    df lower.CL upper.CL\n F      236 2.65  46.4      231      242\n M      242 2.48  47.1      237      247\n\nage = 21:\n Sex emmean   SE    df lower.CL upper.CL\n F      380 2.75  51.4      374      385\n M      385 2.59  55.0      380      390\n\nage = 65:\n Sex emmean   SE    df lower.CL upper.CL\n F      428 3.58 122.2      421      435\n M      431 3.51 138.1      424      438\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n```\n:::\n\n```{.r .cell-code}\npairs(e, reverse = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nage =  7:\n contrast estimate   SE    df t.ratio p.value\n M - F        5.64 3.63  46.7   1.554  0.1269\n\nage = 21:\n contrast estimate   SE    df t.ratio p.value\n M - F        5.53 3.78  53.1   1.462  0.1495\n\nage = 65:\n contrast estimate   SE    df t.ratio p.value\n M - F        2.92 5.01 129.8   0.583  0.5609\n\nDegrees-of-freedom method: kenward-roger \n```\n:::\n:::\n\n\nAnd indeed the sex difference in brain volume is relatively uninteresting at those three ages.\n\nTwo more digressions with `emmeans`. First is computing effect sizes, measured as Cohen's d:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nl <- lmer(MeA ~ ns(age,3) * Sex + (1|subject_id), gf)\ne <- emmeans(l, ~ Sex | age, at = list(age=c(7, 21, 65)))\neff_size(e, sigma=sigma(l), edf=30)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nage =  7:\n contrast effect.size    SE    df lower.CL upper.CL\n F - M         -0.496 0.278  56.0    -1.05   0.0612\n\nage = 21:\n contrast effect.size    SE    df lower.CL upper.CL\n F - M         -1.233 0.329  65.2    -1.89  -0.5766\n\nage = 65:\n contrast effect.size    SE    df lower.CL upper.CL\n F - M         -2.179 0.510 172.9    -3.19  -1.1712\n\nsigma used for effect sizes: 0.04366 \nDegrees-of-freedom method: inherited from kenward-roger when re-gridding \nConfidence level used: 0.95 \n```\n:::\n:::\n\n\nA few things to note:\n\n1.  The effect size function needs the model, the sigma from the linear mixed effects model, and the degrees of freedom of sigma, `edf`. This latter edf is very hard to define, which comes back to acknowledging that the confidence intervals around these effect sizes are going to be somewhat ill defined. Still useful, but keep that in mind.\n\n2.  The direction of the effect sizes has reversed again, and there appears to be no `reverse=TRUE` equivalent to what can be had in `pairs`.\n\nOne more digression on `emmeans`. Since the effects are conditional on the model, that means we can evaluate them at any age, not just those where we had scans. This in turn can be useful for visualizing the temporal evolution of your contrast differences. To wit:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\ne <- emmeans(l, ~ Sex | age, at = list(age=seq(3, 65, by=5)))\nef <- eff_size(e, sigma=sigma(l), edf=30)\ntidy(ef, conf.int = T) %>% \n  ggplot() + \n  aes(x=age, y=estimate*-1, ymin=conf.low*-1, ymax=conf.high*-1) + \n  geom_ribbon(alpha=0.3) + \n  geom_line() + \n  geom_hline(yintercept = 0, linetype=2) + \n  ylab(\"Effect size (male - female)\") + \n  ggtitle(\"Medial Amygdala\", subtitle = \"Effect size of sex difference\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nThis shows the effect sizes of sex in the medial amygdala steadily increasing with age. (And note the multiplication by -1 to get the direction to be what we expected. Also note that we are using the `tidy` function from the `broom` package to get clean output from `emmeans`).\n\n### Using model comparisons\n\nThe downside of the `emmeans` approach is that one has to, in effect, test multiple different ages, which only makes sense when there are precise hypotheses. An alternate approach is to do a set of model comparisons to get at what we would normally think of as main effects. I.e. how much better does the model fit when we include sex? And do we need an interaction? Let's test that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimpleAgeModel <- lmer(MeA ~ ns(age, 3) + (1|subject_id), gf, REML = F)\nAgeAndSexModel <- lmer(MeA ~ ns(age, 3) + Sex + (1|subject_id), gf, REML = F)\nAgeAndSexInteractionModel  <- lmer(MeA ~ ns(age, 3) * Sex + (1|subject_id), gf, REML = F)\n\nanova(simpleAgeModel, AgeAndSexModel, AgeAndSexInteractionModel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: gf\nModels:\nsimpleAgeModel: MeA ~ ns(age, 3) + (1 | subject_id)\nAgeAndSexModel: MeA ~ ns(age, 3) + Sex + (1 | subject_id)\nAgeAndSexInteractionModel: MeA ~ ns(age, 3) * Sex + (1 | subject_id)\n                          npar     AIC     BIC logLik deviance  Chisq Df\nsimpleAgeModel               6 -690.20 -669.73 351.10  -702.20          \nAgeAndSexModel               7 -701.50 -677.62 357.75  -715.50 13.305  1\nAgeAndSexInteractionModel   10 -717.96 -683.84 368.98  -737.96 22.453  3\n                          Pr(>Chisq)    \nsimpleAgeModel                          \nAgeAndSexModel             0.0002647 ***\nAgeAndSexInteractionModel  5.251e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nHere we set up three different statistical models. The first, `simpleAgeModel`, has the third order spline for age but no mention of sex. This effectively becomes our null hypothesis - of course the brain will change with development, but it will not do so in any sex specific way. The second model, `AgeAndSexModel`, includes an additive effect for sex; this would allow for a separate offset by sex, but would keep the slopes between the medial amygdala and age the same for both sexes. The last model `AgeAndSexInteractionModel`, then also allows the age-relation to vary by sex. Once we've computed these three models we run a log-likelihood test between them using the `anova` function, which produces a chi-squared statistic and its associated p-value.\n\n(Note that we fit all the models with `REML=FALSE`. This tells `lmer` to use maximum likelihood, rather than restricted maximum likelihoods as by default. This switch to maximum likelihood estimation is required for the log-likelihood test to be valid when fixed effects are changing between models)\n\nThe results show, in looking at the p values, that the AgeAndSex model is better than the simple age model, and that the one with interactions is the best one of all. So for the medial amygdala sex matters and how it matters changes with age.\n\nLet's retest for overall brain volume where again we should not expect much change:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimpleAgeModel <- lmer(brainVols ~ ns(age, 3) + (1|subject_id), gf, REML = F)\nAgeAndSexModel <- lmer(brainVols ~ ns(age, 3) + Sex + (1|subject_id), gf, REML = F)\nAgeAndSexInteractionModel  <- lmer(brainVols ~ ns(age, 3) * Sex + (1|subject_id), gf, REML = F)\n\nanova(simpleAgeModel, AgeAndSexModel, AgeAndSexInteractionModel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData: gf\nModels:\nsimpleAgeModel: brainVols ~ ns(age, 3) + (1 | subject_id)\nAgeAndSexModel: brainVols ~ ns(age, 3) + Sex + (1 | subject_id)\nAgeAndSexInteractionModel: brainVols ~ ns(age, 3) * Sex + (1 | subject_id)\n                          npar    AIC    BIC  logLik deviance  Chisq Df\nsimpleAgeModel               6 1753.1 1773.6 -870.57   1741.1          \nAgeAndSexModel               7 1752.6 1776.5 -869.29   1738.6 2.5620  1\nAgeAndSexInteractionModel   10 1758.2 1792.3 -869.08   1738.2 0.4193  3\n                          Pr(>Chisq)\nsimpleAgeModel                      \nAgeAndSexModel                0.1095\nAgeAndSexInteractionModel     0.9362\n```\n:::\n:::\n\n\nThis once again says that sex does not play much of a role in shaping the overall size of the brain in mice.\n\nThat's enough for now. Computing all these things across brain structures to follow, alongside a discussion of general additive models and segmented models and how to deal with 3 way interactions, and finally some Bayesian fun likely at the end.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}